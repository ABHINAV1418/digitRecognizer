{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, MaxPool2D\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# the data, split between train and test sets\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data():\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "    # Reshape to be samples*pixels*width*height\n",
    "    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "    X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "    # One hot Cpde\n",
    "    y_train = np_utils.to_categorical(y_train)\n",
    "    y_test = np_utils.to_categorical(y_test)\n",
    "    num_classes = y_test.shape[1]\n",
    "\n",
    "    # convert from integers to floats\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    # normalize to range [0, 1]\n",
    "    X_train = (X_train / 255.0)\n",
    "    X_test = (X_test / 255.0)\n",
    "\n",
    "    return X_test, y_test, X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images.\n",
    "# Flatten each 28x28 image into a 784 dimensional vector\n",
    "\n",
    "def create_model():\n",
    "    # Create model\n",
    "    # Building CNN\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # model.summary()\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------when you dont want to evaluate the model-------------\n",
    "# model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "\n",
    "# # Final evaluation of the model\n",
    "# scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# -------evaluate a model using k-fold cross-validation--------\n",
    "def evaluate_model(X_train, y_Train, n_folds=5):\n",
    "\n",
    "    accuracy, data = list(), list()\n",
    "\n",
    "    # prepare 5-cross validation\n",
    "    kfold = KFold(n_folds, shuffle=True, random_state=1)\n",
    "\n",
    "    for x_train, x_test in kfold.split(X_train):\n",
    "        # create model\n",
    "        model = create_model()\n",
    "        # select rows for train and test\n",
    "        trainX, trainY, testX, testY = X_train[x_train], y_Train[x_train], X_train[x_test], y_Train[x_test]\n",
    "        # fit model\n",
    "        data_fit = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=10, batch_size=32)\n",
    "        # evaluate model\n",
    "        _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "        # stores accuracy\n",
    "        accuracy.append(acc)\n",
    "        data.append(data_fit)\n",
    "    return accuracy, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(data):\n",
    "    for i in range(len(data)):\n",
    "        # plot loss\n",
    "        pyplot.subplot(2, 1, 1)\n",
    "        pyplot.title('Cross Entropy Loss')\n",
    "        pyplot.plot(data[i].history['loss'], color='red', label='green')\n",
    "        pyplot.plot(data[i].history['val_loss'], color='orange', label='test')\n",
    "        # plot accuracy\n",
    "        pyplot.subplot(2, 1, 2)\n",
    "        pyplot.title('Classification Accuracy')\n",
    "        pyplot.plot(data[i].history['accuracy'], color='blue', label='train')\n",
    "        pyplot.plot(data[i].history['val_accuracy'], color='orange', label='test')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize model performance\n",
    "def summarize_performance(acc):\n",
    "    # print summary\n",
    "    print('Accuracy: mean=%.3f std=%.3f, n=%d' % (numpy.mean(acc) * 100, numpy.std(acc) * 100, len(acc)))\n",
    "\n",
    "    # box and whisker plots of results\n",
    "    pyplot.boxplot(acc)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "\n",
    "# This function predicts the images already in the dataset\n",
    "def test(X_train, model):\n",
    "    test_images = X_train[1:5]\n",
    "    test_images = test_images.reshape(test_images.shape[0], 28, 28)\n",
    "\n",
    "    for i, test_image in enumerate(test_images, start=1):\n",
    "        org_image = test_image\n",
    "        test_image = test_image.reshape(1, 28, 28, 1)\n",
    "        prediction = model.predict_classes(test_image, verbose=0)\n",
    "\n",
    "        print(\"Predicted digit: {}\".format(prediction[0]))\n",
    "        plt.subplot(220 + i)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Predicted digit: {}\".format(prediction[0]))\n",
    "        plt.imshow(org_image, cmap=plt.get_cmap('gray'))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    X_test, y_test, X_train, y_train = input_data()\n",
    "\n",
    "    # Evaluate\n",
    "    #accuracy, data = evaluate_model(X_train, y_train)\n",
    "    # summarize_diagnostics(data)\n",
    "    # summarize_performance(accuracy)\n",
    "    model = create_model()\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "    # TEST\n",
    "    # for images alreday\n",
    "    test(X_train, model)\n",
    "\n",
    "\n",
    "    # save model and architecture to single file\n",
    "    model.save(\"model.h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}